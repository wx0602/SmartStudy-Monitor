import sys
import cv2
import json
import time
import numpy as np
import traceback
from pathlib import Path
from PyQt5.QtCore import QThread, pyqtSignal

# å¼•å…¥é…ç½®ç®¡ç†å™¨
try:
    from app.config_manager import ConfigManager
except ImportError:
    # å¤‡ç”¨ï¼šå¦‚æœè·¯å¾„ä¸å¯¹ï¼Œå°è¯•ä»ä¸Šä¸€çº§å¯¼å…¥
    try:
        sys.path.append(str(Path(__file__).resolve().parents[2]))
        from app.config_manager import ConfigManager
    except:
        print("âš ï¸ è­¦å‘Š: ConfigManager å¯¼å…¥å¤±è´¥ï¼Œå°†ä½¿ç”¨é»˜è®¤é…ç½®")
        ConfigManager = None

# ç¡®ä¿èƒ½æ‰¾åˆ° modules æ–‡ä»¶å¤¹ (å®šä½åˆ°é¡¹ç›®æ ¹ç›®å½•)
project_root = Path(__file__).resolve().parents[2]  # æ ¹æ® app/ui/ai_worker.py çš„å±‚çº§è°ƒæ•´
if str(project_root) not in sys.path:
    sys.path.append(str(project_root))

# å°è¯•å¯¼å…¥ AI æ¨¡å— (é˜²æŠ¥é”™æœºåˆ¶)
try:
    from modules.posture.detector import PostureDetector
    from modules.attention.monitor import AttentionMonitor
    from modules.behavior.behavior_detector import BehaviorDetector
except ImportError:
    print("âŒ è­¦å‘Š: æ‰¾ä¸åˆ° modules æ–‡ä»¶å¤¹æˆ– AI æ¨¡å—ï¼ŒAI åŠŸèƒ½å°†å—é™")
    PostureDetector = None
    AttentionMonitor = None
    BehaviorDetector = None

# æ•°æ®åŒ…è£…ç±» (ç”¨äºåœ¨ä¸åŒæ¨¡å—é—´ä¼ é€’ MediaPipe ç»“æœ)
class DetectionResultsWrapper:
    def __init__(self, pose_landmarks, hand_landmarks):
        self.pose_landmarks = pose_landmarks 
        self.multi_hand_landmarks = hand_landmarks

# è¾…åŠ©å‡½æ•°ï¼šå°†è§’åº¦æ ‡å‡†åŒ–åˆ° [-90, 90]
def normalize_angle(angle):
    if angle is None: return 0.0
    while angle > 90: angle -= 180
    while angle < -90: angle += 180
    return round(angle, 2)

# === AI å·¥ä½œçº¿ç¨‹ ===
# åŠŸèƒ½ï¼šåœ¨åå°è¿è¡Œç¹é‡çš„ AI è¿ç®—ï¼Œé¿å…å¡æ­»ç•Œé¢
class AIWorker(QThread):
    # ä¿¡å·ï¼šå°†å¤„ç†å¥½çš„å›¾ç‰‡å‘ç»™ç•Œé¢æ˜¾ç¤º
    change_pixmap_signal = pyqtSignal(np.ndarray)
    # ä¿¡å·ï¼šå°† AI æ•°æ®å­—å…¸å‘ç»™ç•Œé¢æ›´æ–°æ•°å€¼
    update_data_signal = pyqtSignal(dict)

    def __init__(self):
        super().__init__()
        self._run_flag = True
        self.cam_id = 0 # é»˜è®¤æ‘„åƒå¤´ ID
        
        # åˆå§‹åŒ–é…ç½®ç®¡ç†
        self.config_mgr = ConfigManager() if ConfigManager else None
        self.shoulder_thresh = self.config_mgr.get("shoulder_tilt", 10.0) if self.config_mgr else 10.0
        self.neck_thresh = self.config_mgr.get("neck_tilt", 15.0) if self.config_mgr else 15.0

        # æ—¥å¿—è·¯å¾„è®¾ç½®
        self.log_dir = project_root / "logs"
        self.log_file = self.log_dir / "monitor_data.jsonl"
        self.reset_log_file()

        # åˆå§‹åŒ– AI æ¨¡å‹
        self.init_models()

    # åˆå§‹åŒ–æ‰€æœ‰ AI æ¨¡å‹
    def init_models(self):
        try:
            # 1. å§¿æ€æ£€æµ‹
            self.module_a = PostureDetector() if PostureDetector else None
            
            # 2. æ³¨æ„åŠ›æ£€æµ‹ (æ³¨å…¥å…æ ¡å‡†å‚æ•°)
            self.module_b = AttentionMonitor(fps=30) if AttentionMonitor else None
            if self.module_b:
                self.module_b.calibrator.EAR_BASELINE = 0.25
                self.module_b.calibrator.POSE_BASELINE_READY = True
                self.module_b.calibrator.GAZE_BASELINE_READY = True
            
            # 3. è¡Œä¸ºæ£€æµ‹ (ä¼ å…¥é…ç½®)
            config_data = self.config_mgr.data if self.config_mgr else {}
            self.module_c = BehaviorDetector(config_data) if BehaviorDetector else None

            # 4. MediaPipe æ‰‹éƒ¨æ¨¡å‹ (å…³é”®ä¿®å¤ï¼šå…¼å®¹æ€§å¯¼å…¥)
            import mediapipe as mp
            try:
                # å°è¯•æ ‡å‡†æ–¹å¼è·å– solutions
                mp_solutions = mp.solutions
            except AttributeError:
                # å¦‚æœå¤±è´¥ï¼Œå¼ºåˆ¶åŠ è½½ python å­æ¨¡å— (è§£å†³ "no attribute solutions" é”™è¯¯)
                from mediapipe.python import solutions as mp_solutions

            self.mp_hands = mp_solutions.hands.Hands(
                max_num_hands=2, 
                min_detection_confidence=0.5, 
                min_tracking_confidence=0.5
            )
            self.mp_drawing = mp_solutions.drawing_utils
            self.mp_pose_conn = mp_solutions.pose.POSE_CONNECTIONS
            
            print("âœ… AIWorker æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            traceback.print_exc()

    # å¯åŠ¨æ—¶æ¸…ç©ºæ—§æ—¥å¿—
    def reset_log_file(self):
        try:
            if not self.log_dir.exists():
                self.log_dir.mkdir(parents=True, exist_ok=True)
            with open(self.log_file, "w", encoding="utf-8") as f:
                f.write("")
        except Exception: pass

    # ä¿å­˜æ—¥å¿—åˆ°æ–‡ä»¶
    def save_log(self, data_a, data_b, data_c):
        try:
            log_entry = {
                "ts": round(time.time(), 3),
                "posture": {
                    "hunch": bool(data_a.get("is_hunchback")),
                    "lean": bool(data_a.get("is_shoulder_tilted")),
                    "neck": data_a.get("neck_tilt", 0)
                },
                "attention": {
                    "score": int(data_b.get("attention_score", 0)),
                    "fatigue": float(data_b.get("perclos", 0))
                },
                "behavior": {
                    "phone": bool(data_c.get("æ‰‹æœºä½¿ç”¨", {}).get("ä½¿ç”¨æ‰‹æœº"))
                }
            }
            with open(self.log_file, "a", encoding="utf-8") as f:
                f.write(json.dumps(log_entry, ensure_ascii=False) + "\n")
        except Exception: pass

    # çº¿ç¨‹ä¸»å¾ªç¯
    def run(self):
        print("ğŸ“· AIWorker çº¿ç¨‹å·²å¯åŠ¨ï¼Œæ­£åœ¨æ‰“å¼€æ‘„åƒå¤´...")
        cap = cv2.VideoCapture(self.cam_id)
        if not cap.isOpened():
            print("âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
            self.update_data_signal.emit({"Error": "Camera Fail"})
            return
        
        while self._run_flag:
            ret, frame = cap.read()
            if not ret: 
                print("âš ï¸ æ— æ³•è¯»å–è§†é¢‘å¸§")
                break
            
            # é•œåƒç¿»è½¬å¹¶è½¬ RGB
            frame = cv2.flip(frame, 1)
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

            try:
                # --- A: åå§¿æ£€æµ‹ ---
                data_a = {}
                pose_landmarks = None
                if self.module_a:
                    data_a = self.module_a.process_frame(frame)
                    pose_landmarks = data_a.get("landmarks")
                    
                    # è§’åº¦æ ‡å‡†åŒ–
                    s_ang = normalize_angle(data_a.get("shoulder_tilt_angle"))
                    n_ang = normalize_angle(data_a.get("neck_tilt"))
                    
                    data_a["shoulder_tilt_angle"] = s_ang
                    data_a["neck_tilt"] = n_ang
                    # ä½¿ç”¨é…ç½®é˜ˆå€¼åˆ¤æ–­
                    data_a["is_shoulder_tilted"] = abs(s_ang) > self.shoulder_thresh
                    data_a["is_neck_tilted"] = abs(n_ang) > self.neck_thresh

                # --- æ‰‹éƒ¨å…³é”®ç‚¹ ---
                hands_results = None
                if hasattr(self, 'mp_hands'):
                    hands_results = self.mp_hands.process(frame_rgb)

                # --- B: æ³¨æ„åŠ›æ£€æµ‹ ---
                data_b = {}
                if self.module_b:
                    try:
                        res = self.module_b.process(frame)
                        data_b = json.loads(res) if isinstance(res, str) else res
                    except: pass

                # --- C: è¡Œä¸ºæ£€æµ‹ ---
                data_c = {}
                if self.module_c:
                    hand_landmarks = hands_results.multi_hand_landmarks if hands_results else None
                    wrapper = DetectionResultsWrapper(pose_landmarks, hand_landmarks)
                    data_c = self.module_c.process(wrapper, frame=frame)

                # å†™æ—¥å¿— & å‘é€æ•°æ®ç»™ UI
                self.save_log(data_a, data_b, data_c)
                self.update_data_signal.emit({"A": data_a, "B": data_b, "C": data_c})

                self.change_pixmap_signal.emit(frame_rgb)
                
            except Exception as e:
                # æ‰“å°ä¸€æ¬¡é”™è¯¯åé™é»˜ï¼Œé˜²æ­¢åˆ·å±
                if not hasattr(self, "_has_printed_error"):
                    print(f"âš ï¸ AI å¾ªç¯å¤„ç†å‡ºé”™: {e}")
                    traceback.print_exc()
                    self._has_printed_error = True
            
            # æ§åˆ¶å¸§ç‡ (çº¦ 30fps)
            time.sleep(0.03)

        cap.release()
        print("â¹ï¸ AIWorker çº¿ç¨‹å·²åœæ­¢")

    # åœæ­¢çº¿ç¨‹
    def stop(self):
        self._run_flag = False
        self.wait()